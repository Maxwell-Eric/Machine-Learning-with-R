
2. The data set is a list of vehicles. There are 397 observations, which mean there are 397 different vehicles. Each observation or vehicle has 9 variables which describe the attributes. The variables are mpg (number), number of cylinders (integer), engine displacement(number), engine horsepower (character), vehicle weight (integer), acceleration (number), year (integer), origin (integer) and name (character). The horsepower variable is a character, they are all integers in quotes and can be converted to integrers. Although the origin is a number, it is a categorical variable indicating where the vehicle was manufactured. There are three possibile categories for the origin represented by the numbers 1, 2 and 3. 1 seems to represent North America, 2 Europe and 3 Asia. 

5. When looking at the various scatterplots, it would seem that engine displacement, horsepower, and vehicle weight seem to have the most correlation with mpg. They each have a negative correlation with mpg, that is as each of them increase in value the mpg decreases. Although relatively linear, it looks as though all of them might be best fit with a curve. Horse power appears to have the best root mean squared error, while the weight might be the worst RMSE of the three. The displacement has the most outliers. The number of cylinders, year and origin also seem to have a somewhat linear relationship with mpg, however thier RMSE are much higher than the first three attributes mentioned. The acceleration seems to have the least correlation on first glance. The name attribute has already been removed as the name should have no effect on the mpg attribute.

7. I have decided to keep all atributes except the origin. Although there seems to be a small correlation with mpg, the origin of the vehicle probably has little effect on the mpg attribute. I would like to keep all other attributes since there are only six of them. I am going to write functions that will take attribute vectors as parameters. This way, I will be able to test several combinations of attributes quickly to find the best combination for the classifier. 

12. After testing all the combinations of attributes, I found four which gave 99 correct classifications and one incorrect. I chose to use the combination of cylinders, engine displacement, acceleration and year which had a k value of 7. The mis-classified instance was a false positive. It was predicted to have a mpg greater than the median, but did not in reality. This particular configuration had a higher value of k than the other sets with four or more attributes. This low value of k might represent an overfitted data set. All of the k values seemed low for the tests with the highest accuracy. The fact that all of the k values were so low compared to the number of observations probably indicates that my method includes to much variance with a tendency to overfit the data set. Using cross validation would probably help determine if the model was overfit. 




 